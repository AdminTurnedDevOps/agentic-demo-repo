# Core dependencies for Llama fine-tuning with LoRA
torch>=2.0.0
transformers>=4.35.0
peft>=0.7.0
datasets>=2.14.0
accelerate>=0.24.0
bitsandbytes>=0.41.0
scipy>=1.10.0

# Optional but recommended
sentencepiece>=0.1.99
protobuf>=3.20.0
