config:
  tracing:
    otlpEndpoint: "http://127.0.0.1:4317"
    randomSampling: 'true'
    fields:
      add:
        authenticated: 'jwt.sub != null'
        gen_ai.system: 'llm.provider'
        gen_ai.request.model: 'llm.request_model'
        gen_ai.response.model: 'llm.response_model'
        gen_ai.usage.input_tokens: 'llm.input_tokens'
        gen_ai.usage.output_tokens: 'llm.output_tokens'
        gen_ai.operation.name: '"chat"'        
  metrics:
    fields:
      add:
        user_id: "jwt.sub" 
        user_name: 'jwt.preferred_username'
  logging:
    fields:
      add:
        user_id: "jwt.sub" 
        user_name: 'jwt.name'
        authenticated: 'jwt.sub != null'
        jwt_act: "jwt.act"
        token_issuer: 'jwt.iss'
        token_audience: 'jwt.aud'       
        model: 'llm.requestModel'
        provider: 'llm.provider'        
        prompt: 'llm.prompt' 
binds:
- port: 3000
  listeners:
  - routes:
    - backends:
      - ai:
          name: anthropic
          provider:
            anthropic:
              model: "claude-3-5-haiku-latest"
          routes:
            /v1/chat/completions: completions
            /v1/models: passthrough
            '*': passthrough
      policies:
        cors:
          allowOrigins:
          - "*"
          allowHeaders:
          - "*"
        backendAuth:
          key: "$ANTHROPIC_API_KEY"